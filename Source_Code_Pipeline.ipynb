{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d552773",
   "metadata": {},
   "source": [
    "# About this File\n",
    "The purpose of a source code pipeline is to streamline the end-to-end process of treating missing values, label encoding, feature transformation, model building, and preprocessing pipeline for machine learning applications. This involves automating the steps involved in data preprocessing, model development, and deployment, aiming to increase efficiency, consistency, and reproducibility in the development and deployment of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d5341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b014de67",
   "metadata": {},
   "source": [
    "This function is designed to preprocess and clean the input data by handling missing values and creating new features to prepare the data for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014916ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_missing_values(data):\n",
    "    # Columns that are required\n",
    "    columns_to_keep = ['custAge', 'profession', 'marital', 'schooling', 'default', 'housing',\n",
    "                       'loan', 'contact', 'month', 'day_of_week', 'campaign', 'pdays', 'previous',\n",
    "                       'poutcome', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                       'euribor3m', 'nr.employed', 'pmonths', 'pastEmail', 'responded']\n",
    "    \n",
    "    data = data[columns_to_keep]\n",
    "\n",
    "    # Feature engineering for schooling\n",
    "    schooling_category = {\n",
    "        'basic.4y' : 'basic',\n",
    "        'basic.6y' : 'basic',\n",
    "        'basic.9y' : 'basic',\n",
    "        'high.school': 'high.school',\n",
    "        'illiterate':'illiterate',\n",
    "        'professional.course': 'professional.course',\n",
    "        'university.degree':'university.degree',\n",
    "        'unknown':'unknown',\n",
    "    }\n",
    "\n",
    "    data.loc[:,'schooling'] = data['schooling'].replace(schooling_category)\n",
    "\n",
    "    # Imputing the missing values in education based on profession\n",
    "    imputation_mapping = {\n",
    "        'blue-collar' : 'basic',\n",
    "        'self-employed': 'illiterate',\n",
    "        'technician'   : 'professional.course',\n",
    "        'admin.'        : 'university.degree',\n",
    "        'services'      : 'high.school',\n",
    "        'management'    : 'university.degree',\n",
    "        'retired'       : 'unknown',\n",
    "        'entrepreneur'  : 'university.degree'\n",
    "        }\n",
    "\n",
    "    data.loc[:,'schooling'] = data['schooling'].combine_first(data['profession'].map(imputation_mapping))\n",
    "    \n",
    "    # Profession & treating missing values of age\n",
    "    data.loc[:, 'employment_status'] = data['profession'].apply(lambda x: 'retired' if x == 'retired' else ('student' if x == 'student' else 'working'))\n",
    "\n",
    "    # Imputing age values\n",
    "    mean_age_retired = data.loc[data['employment_status'] == 'retired', 'custAge'].mean()\n",
    "    mean_age_student = data.loc[data['employment_status'] == 'student', 'custAge'].mean()\n",
    "    median_age_working = data.loc[data['employment_status'] == 'working', 'custAge'].median()\n",
    "\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'retired') & data['custAge'].isna(), mean_age_retired, data['custAge'])\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'student') & data['custAge'].isna(), mean_age_student, data['custAge'])\n",
    "    data.loc[:,'custAge'] = np.where((data['employment_status'] == 'working') & data['custAge'].isna(), median_age_working, data['custAge'])\n",
    "\n",
    "    # Impute random day for missing 'day_of_week' values\n",
    "    data.loc[:,'day_of_week'] = data['day_of_week'].apply(lambda day: np.random.choice(['mon', 'tue', 'wed', 'thu', 'fri']) if pd.isna(day) else day)\n",
    "\n",
    "    # Drop remaining missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc008e",
   "metadata": {},
   "source": [
    "This function can be used to preprocess the data before training a machine learning model. It helps in converting categorical variables into a format suitable for model training and can also create new features from existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1346b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(data):\n",
    "    # Label encoding for 'profession'\n",
    "    data.loc[:,'profession'] = data['profession'].map({'student': 'Dependents', 'retired': 'Dependents', 'unemployed': 'Unemployed&Unknown', 'unknown': 'Unemployed&Unknown',\n",
    "                                                 'admin.': 'Working', 'blue-collar': 'Working', 'entrepreneur': 'Working', 'housemaid': 'Working',\n",
    "                                                 'management': 'Working', 'self-employed': 'Working', 'services': 'Working', 'technician': 'Working'})\n",
    "\n",
    "    # Label encoding for 'marital'\n",
    "    data.loc[:,'marital'] = data['marital'].map({'single': 'Single&Divorced', 'divorced': 'Single&Divorced', 'married': 'married', 'unknown': 'Unknown'})\n",
    "\n",
    "    # Label encoding for 'schooling'\n",
    "    data.loc[:,'schooling'] = data['schooling'].map({'basic': 'Uneducated&BasicEducation', 'high.school': 'Uneducated&BasicEducation',\n",
    "                                               'illiterate': 'Uneducated&BasicEducation', 'unknown': 'Unknown',\n",
    "                                               'professional.course': 'Educated', 'university.degree': 'Educated'})\n",
    "\n",
    "    # Label encoding for 'default'\n",
    "    data.loc[:,'default'] = data['default'].map({'no': 'No', 'unknown': 'Yes&Unknown', 'yes': 'Yes&Unknown'})\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original data\n",
    "    data_copy_c = data.copy()\n",
    "\n",
    "    # Define a mapping for specific months\n",
    "    quarter_mapping = {'dec': 'QuarterEnd', 'sep': 'QuarterEnd', 'jun': 'QuarterEnd', 'mar': 'QuarterEnd'}\n",
    "\n",
    "    # Replace specified months with 'QuarterEnd' in the copied DataFrame\n",
    "    data_copy_c['month_mapped'] = data_copy_c['month'].replace(quarter_mapping)\n",
    "\n",
    "    # Replace other months with 'others' in the copied DataFrame\n",
    "    data_copy_c['month_mapped'].replace(to_replace=data_copy_c['month_mapped'][~data_copy_c['month_mapped'].isin(['QuarterEnd'])].unique(), value='others', inplace=True)\n",
    "\n",
    "    data.loc[:,'month'] = data_copy_c['month_mapped']\n",
    "\n",
    "    # Label encoding for 'day_of_week'\n",
    "    data.loc[:,'day_of_week'] = data['day_of_week'].map({'mon': 'WeekBeginning', 'tue': 'WeekBeginning', 'wed': 'WeekBeginning',\n",
    "                                                   'thu': 'WeekEnding', 'fri': 'WeekEnding'})\n",
    "\n",
    "    # Feature engineering of other variables\n",
    "    # pdays\n",
    "    conditions = [\n",
    "        (data['pdays'] == 999),\n",
    "        (data['pdays'] < 5),\n",
    "        ((data['pdays'] >= 5) & (data['pdays'] <= 10)),\n",
    "        (data['pdays'] > 10)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 5 days', '5 to 10 days', 'greater than 10 days']\n",
    "\n",
    "    # Create the 'pduration' column based on conditions\n",
    "    data.loc[:,'pduration'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    # pmonths\n",
    "    conditions = [\n",
    "        (data['pmonths'] == 999),\n",
    "        (data['pmonths'] <= 0.2),\n",
    "        (data['pmonths'] > 0.2)\n",
    "    ]\n",
    "\n",
    "    choices = ['first visit', 'less than 2 months', 'greater than 2 months']\n",
    "\n",
    "    # Create the 'pduration' column based on conditions\n",
    "    data['pduration_m'] = np.select(conditions, choices, default='unknown')\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7f4ff",
   "metadata": {},
   "source": [
    "The provided Python function performs feature transformation on a given dataset. It includes several key steps to prepare the data for machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61413918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "def feature_transformation(data):\n",
    "    # Drop target and unnecessary columns\n",
    "    X = data.drop(['responded', 'pdays', 'pmonths', 'employment_status'], axis=1)\n",
    "    y = data['responded']\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    X_encoded = pd.get_dummies(X, columns=['loan', 'marital', 'schooling', 'default', 'housing', 'day_of_week',\n",
    "                                           'poutcome', 'pduration', 'pduration_m', 'profession', 'month', 'contact'], drop_first=True)\n",
    "\n",
    "    # Identify continuous columns for normalization\n",
    "    continuous_columns = ['custAge', 'campaign', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx',\n",
    "                           'euribor3m', 'nr.employed', 'pastEmail']\n",
    "\n",
    "    # Extract the continuous columns from X_encoded\n",
    "    X_continuous = X_encoded[continuous_columns]\n",
    "\n",
    "    # Instantiate StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit and transform the scaler on the continuous data\n",
    "    X_continuous_normalized = scaler.fit_transform(X_continuous)\n",
    "\n",
    "    # Replace the original continuous columns in X_encoded with the normalized ones\n",
    "    X_encoded[continuous_columns] = X_continuous_normalized\n",
    "\n",
    "    return X_encoded, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7466cffd",
   "metadata": {},
   "source": [
    "In this training model a random seed provides consistency and reproducibility in the generation of random numbers, which is critical for the development and evaluation of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "726ead83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_propensify_model(X_encoded, y):\n",
    "    # Set a random seed for reproducibility\n",
    "    np.random.seed(78)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=78)\n",
    "    \n",
    "    # Define RandomForestClassifier\n",
    "    rf = RandomForestClassifier()\n",
    "    \n",
    "    # Define parameter grid for Random Forest\n",
    "    param_grid = {\n",
    "       'n_estimators': [10, 20, 30],\n",
    "       'max_depth': [None, 10, 20],\n",
    "       'min_samples_split': [2, 5, 10],\n",
    "       'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Perform GridSearchCV for hyperparameter tuning\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Apply SMOTEENN to the training data\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # Create a Support Vector Machine (SVM) classifier with tuned parameters\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "    # Ensemble the classifiers using a VotingClassifier\n",
    "    ensemble_classifier = VotingClassifier(estimators=[\n",
    "        ('rf', rf),\n",
    "        ('svm', svm_classifier)\n",
    "    ], voting='hard')  # 'hard' for probability voting\n",
    "\n",
    "    # Fit the ensemble model on the resampled training data\n",
    "    ensemble_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "\n",
    "    return ensemble_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66409b7a",
   "metadata": {},
   "source": [
    "Load tain and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc89138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_excel(r\"C:\\Users\\Zimm\\Downloads\\Propensify\\train.xlsx\")\n",
    "test_data = pd.read_excel(r\"C:\\Users\\Zimm\\Downloads\\Propensify\\test.xlsx\")\n",
    "test_data['responded'] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049dfcc",
   "metadata": {},
   "source": [
    "Analyse the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17648f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['propensify.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_pipeline = Pipeline([\n",
    "    ('missing_values', FunctionTransformer(func=treat_missing_values)),\n",
    "    ('label_encoding', FunctionTransformer(func=label_encoding)),\n",
    "    ('feature_transformation', FunctionTransformer(func=feature_transformation)),\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "X_train_transformed, y_train = preprocessing_pipeline.fit_transform(train_data)\n",
    "\n",
    "# Train model using the transformed data\n",
    "trained_model = train_propensify_model(X_train_transformed, y_train)\n",
    "\n",
    "# Save the preprocessing pipeline\n",
    "joblib.dump(preprocessing_pipeline, 'preprocessing_pipeline.joblib')\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(trained_model, 'propensify.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae8aae",
   "metadata": {},
   "source": [
    "Load the train model and preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1454b3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = joblib.load('propensify.joblib')\n",
    "\n",
    "preprocessing_pipeline = joblib.load('preprocessing_pipeline.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1419dd34",
   "metadata": {},
   "source": [
    "Analyze the test data on pipeline transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af73855",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed, _ = preprocessing_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d9b312",
   "metadata": {},
   "source": [
    "Predictions on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc589ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = load_model.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "711dddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custAge</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>pastEmail</th>\n",
       "      <th>loan_unknown</th>\n",
       "      <th>...</th>\n",
       "      <th>pduration_first visit</th>\n",
       "      <th>pduration_greater than 10 days</th>\n",
       "      <th>pduration_less than 5 days</th>\n",
       "      <th>pduration_m_greater than 2 months</th>\n",
       "      <th>pduration_m_less than 2 months</th>\n",
       "      <th>profession_Unemployed&amp;Unknown</th>\n",
       "      <th>profession_Working</th>\n",
       "      <th>month_others</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>Predicted_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.188221</td>\n",
       "      <td>-0.207980</td>\n",
       "      <td>1.713222</td>\n",
       "      <td>-0.763555</td>\n",
       "      <td>1.076265</td>\n",
       "      <td>0.650961</td>\n",
       "      <td>-1.593395</td>\n",
       "      <td>-2.849255</td>\n",
       "      <td>1.354201</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.507809</td>\n",
       "      <td>-0.207980</td>\n",
       "      <td>1.713222</td>\n",
       "      <td>-2.231472</td>\n",
       "      <td>-2.077163</td>\n",
       "      <td>2.321153</td>\n",
       "      <td>-1.650120</td>\n",
       "      <td>-2.097493</td>\n",
       "      <td>1.354201</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.090129</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>1.713222</td>\n",
       "      <td>-1.210312</td>\n",
       "      <td>-1.186580</td>\n",
       "      <td>-1.236139</td>\n",
       "      <td>-1.338134</td>\n",
       "      <td>-0.959390</td>\n",
       "      <td>1.354201</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.040455</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>0.832007</td>\n",
       "      <td>-0.231888</td>\n",
       "      <td>0.954632</td>\n",
       "      <td>0.767049</td>\n",
       "      <td>0.839818</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.081692</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>-0.125330</td>\n",
       "      <td>-0.654655</td>\n",
       "      <td>-0.325125</td>\n",
       "      <td>0.297622</td>\n",
       "      <td>0.389319</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32945</th>\n",
       "      <td>-0.188221</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>0.640540</td>\n",
       "      <td>0.721071</td>\n",
       "      <td>0.889560</td>\n",
       "      <td>0.705114</td>\n",
       "      <td>0.322371</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32946</th>\n",
       "      <td>-0.827396</td>\n",
       "      <td>0.508043</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>-1.210312</td>\n",
       "      <td>-1.186580</td>\n",
       "      <td>-1.236139</td>\n",
       "      <td>-1.373442</td>\n",
       "      <td>-0.959390</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>-0.827396</td>\n",
       "      <td>-0.207980</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>-1.210312</td>\n",
       "      <td>-1.186580</td>\n",
       "      <td>-1.236139</td>\n",
       "      <td>-1.354341</td>\n",
       "      <td>-0.959390</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32948</th>\n",
       "      <td>-0.827396</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>0.832007</td>\n",
       "      <td>1.537150</td>\n",
       "      <td>-0.281744</td>\n",
       "      <td>0.764154</td>\n",
       "      <td>0.839818</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32949</th>\n",
       "      <td>-1.573101</td>\n",
       "      <td>-0.207980</td>\n",
       "      <td>-0.347067</td>\n",
       "      <td>-1.912359</td>\n",
       "      <td>-1.065294</td>\n",
       "      <td>-0.064836</td>\n",
       "      <td>-1.376915</td>\n",
       "      <td>-1.278784</td>\n",
       "      <td>-0.274884</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32145 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        custAge  campaign  previous  emp.var.rate  cons.price.idx  \\\n",
       "0     -0.188221 -0.207980  1.713222     -0.763555        1.076265   \n",
       "1     -0.507809 -0.207980  1.713222     -2.231472       -2.077163   \n",
       "2      1.090129 -0.565991  1.713222     -1.210312       -1.186580   \n",
       "3     -1.040455 -0.565991 -0.347067      0.832007       -0.231888   \n",
       "4     -0.081692 -0.565991 -0.347067     -0.125330       -0.654655   \n",
       "...         ...       ...       ...           ...             ...   \n",
       "32945 -0.188221 -0.565991 -0.347067      0.640540        0.721071   \n",
       "32946 -0.827396  0.508043 -0.347067     -1.210312       -1.186580   \n",
       "32947 -0.827396 -0.207980 -0.347067     -1.210312       -1.186580   \n",
       "32948 -0.827396 -0.565991 -0.347067      0.832007        1.537150   \n",
       "32949 -1.573101 -0.207980 -0.347067     -1.912359       -1.065294   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed  pastEmail  loan_unknown  ...  \\\n",
       "0           0.650961  -1.593395    -2.849255   1.354201             0  ...   \n",
       "1           2.321153  -1.650120    -2.097493   1.354201             0  ...   \n",
       "2          -1.236139  -1.338134    -0.959390   1.354201             0  ...   \n",
       "3           0.954632   0.767049     0.839818  -0.274884             0  ...   \n",
       "4          -0.325125   0.297622     0.389319  -0.274884             0  ...   \n",
       "...              ...        ...          ...        ...           ...  ...   \n",
       "32945       0.889560   0.705114     0.322371  -0.274884             0  ...   \n",
       "32946      -1.236139  -1.373442    -0.959390  -0.274884             0  ...   \n",
       "32947      -1.236139  -1.354341    -0.959390  -0.274884             0  ...   \n",
       "32948      -0.281744   0.764154     0.839818  -0.274884             0  ...   \n",
       "32949      -0.064836  -1.376915    -1.278784  -0.274884             0  ...   \n",
       "\n",
       "       pduration_first visit  pduration_greater than 10 days  \\\n",
       "0                          1                               0   \n",
       "1                          0                               0   \n",
       "2                          1                               0   \n",
       "3                          1                               0   \n",
       "4                          1                               0   \n",
       "...                      ...                             ...   \n",
       "32945                      1                               0   \n",
       "32946                      1                               0   \n",
       "32947                      1                               0   \n",
       "32948                      1                               0   \n",
       "32949                      1                               0   \n",
       "\n",
       "       pduration_less than 5 days  pduration_m_greater than 2 months  \\\n",
       "0                               0                                  0   \n",
       "1                               1                                  0   \n",
       "2                               0                                  0   \n",
       "3                               0                                  0   \n",
       "4                               0                                  0   \n",
       "...                           ...                                ...   \n",
       "32945                           0                                  0   \n",
       "32946                           0                                  0   \n",
       "32947                           0                                  0   \n",
       "32948                           0                                  0   \n",
       "32949                           0                                  0   \n",
       "\n",
       "       pduration_m_less than 2 months  profession_Unemployed&Unknown  \\\n",
       "0                                   0                              0   \n",
       "1                                   1                              0   \n",
       "2                                   0                              0   \n",
       "3                                   0                              0   \n",
       "4                                   0                              0   \n",
       "...                               ...                            ...   \n",
       "32945                               0                              0   \n",
       "32946                               0                              0   \n",
       "32947                               0                              0   \n",
       "32948                               0                              0   \n",
       "32949                               0                              0   \n",
       "\n",
       "       profession_Working  month_others  contact_telephone  Predicted_Response  \n",
       "0                       1             0                  0                 yes  \n",
       "1                       1             0                  0                 yes  \n",
       "2                       1             1                  0                  no  \n",
       "3                       1             1                  0                  no  \n",
       "4                       1             1                  0                  no  \n",
       "...                   ...           ...                ...                 ...  \n",
       "32945                   1             1                  1                  no  \n",
       "32946                   1             1                  0                 yes  \n",
       "32947                   1             1                  0                 yes  \n",
       "32948                   1             0                  1                  no  \n",
       "32949                   1             0                  1                 yes  \n",
       "\n",
       "[32145 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add a new column 'Predictions' to the preprocessed test data\n",
    "X_test_transformed['Predicted_Response'] = predictions\n",
    "\n",
    "# Display the DataFrame with all columns and predictions\n",
    "display(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936e1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     23931\n",
       "yes     8214\n",
       "Name: Predicted_Response, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed['Predicted_Response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de48f405",
   "metadata": {},
   "source": [
    "Saved the result to csv and excel. Because the data are in xlsx format while in the project Task/Activities list asking for \"testingCandidate.csv\" file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d689729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'testing_Candidate.csv'\n",
    "X_test_transformed.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b76fc29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = 'testing_Candidate.xlsx'\n",
    "X_test_transformed.to_excel(excel_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78bdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
